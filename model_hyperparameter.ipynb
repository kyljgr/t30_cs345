{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = pd.read_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cities and temperature types\n",
    "cities = ['DRESDEN', 'KASSEL', 'DUSSELDORF']\n",
    "temp_types = ['temp_mean', 'temp_max', 'temp_min']\n",
    "\n",
    "# Dictionary to store models\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4031\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 9.821587\n",
      "Mean Squared Error for DRESDEN temp_mean: 2.3945900848391295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4031\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 13.692268\n",
      "Mean Squared Error for DRESDEN temp_max: 3.4981556332106933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4031\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 5.952241\n",
      "Mean Squared Error for DRESDEN temp_min: 3.9075183776014977\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4047\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 9.577660\n",
      "Mean Squared Error for KASSEL temp_mean: 0.9492065687875183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4047\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 13.821998\n",
      "Mean Squared Error for KASSEL temp_max: 1.6311819481338548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4047\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 5.584434\n",
      "Mean Squared Error for KASSEL temp_min: 2.3369359460765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4051\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 11.129217\n",
      "Mean Squared Error for DUSSELDORF temp_mean: 1.3650221147521289\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4051\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 15.299555\n",
      "Mean Squared Error for DUSSELDORF temp_max: 2.031505176571656\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4051\n",
      "[LightGBM] [Info] Number of data points in the train set: 2923, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 6.835854\n",
      "Mean Squared Error for DUSSELDORF temp_min: 2.925706846251895\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    for temp_type in temp_types:\n",
    "        # Prepare features and target\n",
    "        features = data.drop(columns=['DATE'] + [f'{city}_{t}' for t in temp_types])\n",
    "        target = data[f'{city}_{temp_type}']\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "        \n",
    "        grid = [\n",
    "            {'n_estimators': [1, 10, 100, 1000], \n",
    "            'learning_rate': [0.001, 0.01, 0.1], \n",
    "            'subsample_for_bin': [200, 2000, 20000, 200000],\n",
    "            'num_leaves': [10, 15, 20, 30, 45]},\n",
    "            ]\n",
    "        # Create and train the LightGBM model\n",
    "        model = lgb.LGBMRegressor(n_estimators = 1000, learning_rate=0.1, subsample_for_bin=200000, num_leaves=12)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Store the model\n",
    "        models[f'{city}_{temp_type}'] = model\n",
    "        \n",
    "        # Predictions and evaluations\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Calculate and print mean squared error\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        print(f'Mean Squared Error for {city} {temp_type}: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new data to test on custom input\n",
    "new_data = {\n",
    "    'DRESDEN_wind_speed': [3.5],\n",
    "    'DRESDEN_wind_gust': [10.2],\n",
    "    'DRESDEN_humidity': [0.85],\n",
    "    'DRESDEN_global_radiation': [0.15],\n",
    "    'DRESDEN_precipitation': [0.00],\n",
    "    'DRESDEN_sunshine': [5.0],\n",
    "    'DUSSELDORF_temp_mean': [10.0], \n",
    "    'DUSSELDORF_temp_max': [15.0],   \n",
    "    'DUSSELDORF_temp_min': [5.0],   \n",
    "    'DUSSELDORF_wind_speed': [4.0],\n",
    "    'DUSSELDORF_wind_gust': [12.5],\n",
    "    'DUSSELDORF_humidity': [0.80],\n",
    "    'DUSSELDORF_global_radiation': [0.20],\n",
    "    'DUSSELDORF_precipitation': [0.05],\n",
    "    'DUSSELDORF_sunshine': [6.0],\n",
    "    'KASSEL_temp_mean': [9.0],     \n",
    "    'KASSEL_temp_max': [14.0],     \n",
    "    'KASSEL_temp_min': [4.0],   \n",
    "    'KASSEL_wind_speed': [2.8],\n",
    "    'KASSEL_wind_gust': [11.0],\n",
    "    'KASSEL_humidity': [0.88],\n",
    "    'KASSEL_global_radiation': [0.18],\n",
    "    'KASSEL_precipitation': [0.02],\n",
    "    'KASSEL_sunshine': [4.5]\n",
    "}\n",
    "\n",
    "\n",
    "new_features = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted temp_mean for DRESDEN: 9.024635003796599\n",
      "Predicted temp_max for DRESDEN: 13.014866038809078\n",
      "Predicted temp_min for DRESDEN: 6.059938809650521\n",
      "Predicted temp_mean for KASSEL: 3.848618371312498\n",
      "Predicted temp_max for KASSEL: 8.650193518588503\n",
      "Predicted temp_min for KASSEL: 0.5373902165783453\n",
      "Predicted temp_mean for DUSSELDORF: 10.751389483831108\n",
      "Predicted temp_max for DUSSELDORF: 15.624842273030392\n",
      "Predicted temp_min for DUSSELDORF: 5.26486236605847\n"
     ]
    }
   ],
   "source": [
    "# Predict and print results for each city and temperature type\n",
    "for city in cities:\n",
    "    for temp_type in temp_types:\n",
    "        model = models[f'{city}_{temp_type}']  # Retrieve the model\n",
    "        predicted_temp = model.predict(new_features)\n",
    "        print(f\"Predicted {temp_type} for {city}: {predicted_temp[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_size closer to 1 creates a larger MSE, which is not good. \n",
    "\n",
    "smaller subsample_for_data creates a larger MSE\n",
    "\n",
    "changing n_estimators does not seem to drastically change the MSE\n",
    "\n",
    "giving max_depth a limit like 3 makes MSE higher\n",
    "\n",
    "changing boosting_type either gave an error or didn't change the MSE drastically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
